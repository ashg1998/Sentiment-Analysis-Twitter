{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import (RandomUnderSampler,\n",
    "NearMiss,\n",
    "InstanceHardnessThreshold,\n",
    "CondensedNearestNeighbour,\n",
    "EditedNearestNeighbours,\n",
    "RepeatedEditedNearestNeighbours,\n",
    "AllKNN,\n",
    "NeighbourhoodCleaningRule,\n",
    "OneSidedSelection,\n",
    "TomekLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "ps = PorterStemmer()\n",
    "def all_the_cooking(line):\n",
    "    reviews = re.sub('[^a-zA-Z]' , ' ', line)\n",
    "    reviews = reviews.lower()\n",
    "    reviews = reviews.split()\n",
    "    reviews = [ps.stem(word) for word in reviews if not word in set(stopwords.words('english'))]\n",
    "    reviews = ' '.join(reviews)\n",
    "    return(reviews)\n",
    "for i,line in enumerate(data.tweet):\n",
    "    data.tweet[i] = all_the_cooking(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_x,train_y,test_x,test_y):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X=train_x , y = train_y)\n",
    "    expected = test_y\n",
    "    predicted=model.predict(test_x)\n",
    "    from sklearn import metrics\n",
    "    print(metrics.classification_report(expected, predicted))\n",
    "    print(metrics.confusion_matrix(expected, predicted))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EditedNearestNeighbours(kind_sel='all', n_jobs=1, n_neighbors=3,\n",
      "                        random_state=None, ratio=None, return_indices=False,\n",
      "                        sampling_strategy='auto')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      5240\n",
      "           1       0.99      0.14      0.25       579\n",
      "\n",
      "    accuracy                           0.91      5819\n",
      "   macro avg       0.95      0.57      0.60      5819\n",
      "weighted avg       0.92      0.91      0.88      5819\n",
      "\n",
      "[[5239    1]\n",
      " [ 498   81]]\n"
     ]
    }
   ],
   "source": [
    "sampler = EditedNearestNeighbours()\n",
    "enn_xtrain_tfidf, enn_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(enn_xtrain_tfidf, enn_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepeatedEditedNearestNeighbours(kind_sel='all', max_iter=100, n_jobs=1,\n",
      "                                n_neighbors=3, random_state=None, ratio=None,\n",
      "                                return_indices=False, sampling_strategy='auto')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1406\n",
      "           1       0.99      0.72      0.84       533\n",
      "\n",
      "    accuracy                           0.92      1939\n",
      "   macro avg       0.95      0.86      0.89      1939\n",
      "weighted avg       0.93      0.92      0.92      1939\n",
      "\n",
      "[[1404    2]\n",
      " [ 147  386]]\n"
     ]
    }
   ],
   "source": [
    "sampler = RepeatedEditedNearestNeighbours()\n",
    "enn_xtrain_tfidf, enn_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(enn_xtrain_tfidf, enn_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllKNN(allow_minority=True, kind_sel='all', n_jobs=1, n_neighbors=3,\n",
      "       random_state=None, ratio=None, return_indices=False,\n",
      "       sampling_strategy='auto')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      5282\n",
      "           1       0.98      0.15      0.27       574\n",
      "\n",
      "    accuracy                           0.92      5856\n",
      "   macro avg       0.95      0.58      0.61      5856\n",
      "weighted avg       0.92      0.92      0.89      5856\n",
      "\n",
      "[[5280    2]\n",
      " [ 486   88]]\n"
     ]
    }
   ],
   "source": [
    "sampler = AllKNN(allow_minority=True)\n",
    "enn_xtrain_tfidf, enn_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(enn_xtrain_tfidf, enn_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = CondensedNearestNeighbour(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nm_xtrain_tfidf, nm_train_y = sampler.fit_sample(tfid_data_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(nm_xtrain_tfidf, nm_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneSidedSelection(n_jobs=1, n_neighbors=None, n_seeds_S=1, random_state=0,\n",
      "                  ratio=None, return_indices=False, sampling_strategy='auto')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7456\n",
      "           1       1.00      0.16      0.27       526\n",
      "\n",
      "    accuracy                           0.94      7982\n",
      "   macro avg       0.97      0.58      0.62      7982\n",
      "weighted avg       0.95      0.94      0.92      7982\n",
      "\n",
      "[[7456    0]\n",
      " [ 444   82]]\n"
     ]
    }
   ],
   "source": [
    "sampler = OneSidedSelection(random_state=0)\n",
    "nm_xtrain_tfidf, nm_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(nm_xtrain_tfidf, nm_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeighbourhoodCleaningRule(kind_sel='all', n_jobs=1, n_neighbors=3,\n",
      "                          random_state=None, ratio=None, return_indices=False,\n",
      "                          sampling_strategy='auto', threshold_cleaning=0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7224\n",
      "           1       1.00      0.13      0.24       553\n",
      "\n",
      "    accuracy                           0.94      7777\n",
      "   macro avg       0.97      0.57      0.60      7777\n",
      "weighted avg       0.94      0.94      0.92      7777\n",
      "\n",
      "[[7224    0]\n",
      " [ 479   74]]\n"
     ]
    }
   ],
   "source": [
    "sampler = NeighbourhoodCleaningRule()\n",
    "nm_xtrain_tfidf, nm_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(nm_xtrain_tfidf, nm_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEENN(enn=None, n_jobs=1, random_state=42, ratio=None,\n",
      "         sampling_strategy='auto', smote=None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86      1381\n",
      "           1       0.96      1.00      0.98      7374\n",
      "\n",
      "    accuracy                           0.96      8755\n",
      "   macro avg       0.98      0.88      0.92      8755\n",
      "weighted avg       0.96      0.96      0.96      8755\n",
      "\n",
      "[[1047  334]\n",
      " [   0 7374]]\n"
     ]
    }
   ],
   "source": [
    "sampler = SMOTEENN(random_state=42)\n",
    "nm_xtrain_tfidf, nm_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(nm_xtrain_tfidf, nm_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "tfid_data_x = vect.fit_transform(data['tweet'])\n",
    "train_y  = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTETomek(n_jobs=1, random_state=42, ratio=None, sampling_strategy='auto',\n",
      "           smote=None, tomek=None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.94      7451\n",
      "           1       0.92      0.98      0.95      7409\n",
      "\n",
      "    accuracy                           0.95     14860\n",
      "   macro avg       0.95      0.95      0.95     14860\n",
      "weighted avg       0.95      0.95      0.95     14860\n",
      "\n",
      "[[6822  629]\n",
      " [ 172 7237]]\n"
     ]
    }
   ],
   "source": [
    "sampler = SMOTETomek(random_state=42)\n",
    "nm_xtrain_tfidf, nm_train_y = sampler.fit_sample(tfid_data_x, train_y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(nm_xtrain_tfidf, nm_train_y)\n",
    "print(sampler)\n",
    "train_model(train_x,train_y ,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
