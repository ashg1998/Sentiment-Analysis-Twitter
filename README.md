# Sentiment-Analysis-Twitter

In this project ,we are trying to figure out the sentiments by using twitter post.
Now after receiving the data , I have explpred the data and found that there were 92% negative feedback and 8% positive. So the data is highly imbalanced.
To overcome this problem various to handle imbalanced techniques are used including both  Over-Sampling and Under-Sampling
Evaluating Metric:
F1-Score: which is the weighted average of Precision and Recall.
F1 Score = 2*(Recall * Precision) / (Recall + Precision)

Classifier Used: MultinomialNB()

Over-Sampling:
Over-sampling is used when the quantity of data is insufficient. It attempts to balance the data-set by increasing the size of minority samples. Rather than getting rid of majority samples, new minority samples are generated by using: repetition, bootstrapping, SMOTE (Synthetic Minority Over-Sampling Technique) or ADASYN (Adaptive synthetic sampling).
1) Resampling: using sklearn.utils Resampling()
  precision    recall  f1-score   support

           0       0.97      0.90      0.94     14860
           1       0.91      0.98      0.94     14860

2) SMOTE:
SMOTE is a Synthetic minority over-sampling approach in which the minority class is over-sampled by creating “synthetic” samples rather than creating new random minority samples from existing minority classes.
 precision    recall  f1-score   support

           0       0.94      1.00      0.97     14860
           1       1.00      0.12      0.21      1121

3) ADASYN: Adaptive synthetic sampling (Over-sampling) 
The advantage of ADASYN over SMOTE is the use a weighted distribution for different minority class samples according to their level of difficulty in learning, where more synthetic data is generated for minority class samples that are harder to learn compared to those minority samples that are easier to learn.
 precision    recall  f1-score   support

           0       0.98      0.90      0.94      7392
           1       0.91      0.98      0.94      7395
           
  4)SMOTE-NC uses SMOTE approach by synthesizing new minority samples but slightly change the way a new sample is generated by performing something specific for the categorical features. In fact, the categories of a new generated sample are decided by picking the most frequent category of the nearest neighbors present during the generation:
  precision    recall  f1-score   support

           0       1.00      0.94      0.97      7453
           1       0.94      1.00      0.97      7407
  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
   Under-Sampling:
   1) Random Under Sampling
   Random under-sampling is a controlled under-sampling method, where the number of samples to be selected can be defined. This method randomly reduces the majority classes in order to make the balance, let us see the evaluation:
   precision    recall  f1-score   support

           0       0.92      0.80      0.85       576
           1       0.81      0.92      0.86       545
2) NearMiss
NearMiss method is part of the imbalance learn library, NearMiss implements heuristic rules in order to select samples. It performs under-sampling of samples in the majority class based on their distance to other samples in the same class. This method uses three different variants:

NearMiss-1 retain samples from the majority class for which the average distance of the k ( tunable hyperparameter) nearest samples of the minority class is the smallest.

NearMiss-2 keeps the samples from majority class whose mean distance to the k furthest samples in the minority class is lowest.

NearMiss-3 selects k nearest neighbors in majority class for every sample in the minority class. So under-sampling ratio is directly controlled by k and is not separately tuned.

 precision    recall  f1-score   support

           0       0.87      0.84      0.85       597
           1       0.83      0.85      0.84       524
3) Tomek Link Removal
A pair of samples is called a Tomek link if they belong to different classes and are each other’s nearest neighbors. Under-sampling can be done by removing all tomek links from the dataset. 
ecision    recall  f1-score   support

           0       0.94      1.00      0.97      7410
           1       0.99      0.16      0.27       572
           
4)Edited Nearest Neighbor (ENN)
ENN under samples the majority class by removing samples which their class differs from the one of their nearest neighbors. If this step is repeated then we drive a new method RepeatedEditedNearestNeighbours
Another driven method: AllKNN is slightly different from the RepeatedEditedNearestNeighbours by changing the k parameter of the internal nearest neighbors algorithm, increasing it at each iteration. The last two algorithms require higher processing time
#EditedNearestNeighbours():
precision    recall  f1-score   support

           0       0.91      1.00      0.95      5240
           1       0.99      0.14      0.25       579
#RepeatedEditedNearestNeighbours():
precision    recall  f1-score   support

           0       0.91      1.00      0.95      1406
           1       0.99      0.72      0.84       533
#AllKNN()
precision    recall  f1-score   support

           0       0.92      1.00      0.96      5282
           1       0.98      0.15      0.27       5745
           
           
5)Condensed Nearest Neighbor (CNN)
CNN makes use of a 1st nearest neighbor (1-NN) to iteratively decide if a sample should be kept in a data-set or not. Under-sampling via CNN can be slower compared to other methods since it requires many passes over the training data. CNN is considered noise sensitive and preserves the noisy samples. Another driven method OneSidedSelection also used the 1-NN and use TomekLinks discussed above to remove the samples considered noisy. The NeighbourhoodCleaningRule which is also driven from CNN uses EditedNearestNeighbours to remove some sample.
#OneSidedSelection()
precision    recall  f1-score   support

           0       0.94      1.00      0.97      7456
           1       1.00      0.16      0.27       526
#NeighbourhoodCleaningRule()
precision    recall  f1-score   support

           0       0.94      1.00      0.97      7224
           1       1.00      0.13      0.24       553
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Combining Under and Over Sampling
There are other methods to Over and Under Sample, but how about combining both? 
SMOTE + ENN
:SMOTEENN(enn=None, n_jobs=1, random_state=42, ratio=None,
         sampling_strategy='auto', smote=None)
              precision    recall  f1-score   support

           0       1.00      0.76      0.86      1381
           1       0.96      1.00      0.98      7374


But another approach SMOTE + Tomek Link Removal
 precision    recall  f1-score   support

           0       0.98      0.92      0.94      7451
           1       0.92      0.98      0.95      7409

Conclusion:
It is seen that combining Under and Over Sampling ,gives the best result 
SMOTE + ENN
:SMOTEENN(enn=None, n_jobs=1, random_state=42, ratio=None,
         sampling_strategy='auto', smote=None)
              precision    recall  f1-score   support

           0       1.00      0.76      0.86      1381
           1       0.96      1.00      0.98      7374

SMOTE + Tomek Link Removal
 precision    recall  f1-score   support

           0       0.98      0.92      0.94      7451
           1       0.92      0.98      0.95      7409
           

  
